<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="width-device,initial-Scale=1">
    <title>Disadventages of AI</title>
</head>
<body background="https://images.financialexpress.com/2021/03/artificial-intelligence.jpg" width="300"height="280">
    <ul>
        <li><a href="Home.html">Home Page</a></li>
        <li><a href="advantages of AI.html"> advantages</a></li>
        <li><a href="disadventages.html">disadventages</a></li>
        <li><a href="importanceofAI.">importanceofAI</a></li>
    </ul>
    <img src="https://data-flair.training/blogs/wp-content/uploads/sites/2/2019/09/Pros-and-Cons-of-Artificial-Intelligence-1200x720.jpg">
    <h2><span class="ez-toc-section" id="The_Cons_of_AI"></span>The Cons of AI<span class="ez-toc-section-end"></span></h2>
    <h3><span class="ez-toc-section" id="1_Uncontrollability"></span>1. Uncontrollability&nbsp;<span class="ez-toc-section-end"></span></h3>
    <p>There is credibility to the fears of AI as encapsulated by SciFi writers and echoed by those such as Hawking and Musk. Advanced AI is indeed a new horizon and we do not yet understand its limits and how careful we need to be in its development.&nbsp;</p>
    <p>Whilst we may generally consider that an inventor always retains ultimate control over their invention, with AI, this may not be the case. We have already seen some evidence of unexpected AI behaviour, such as DeepMind exhibiting <a href="https://www.sciencealert.com/google-deep-mind-has-learned-to-become-highly-aggressive-in-stressful-situations" target="_blank" rel="nofollow">‘aggressive’ behaviour during tests</a> designed to assess how well it cooperated with others during stressful situations. Once AI becomes autonomous or liberated from its designer <em>and </em>highly intelligent, that is when Pandora’s Box is really opened. Though we might typically imagine this as a rogue intelligent robot that escapes the clutches of its inventor, intelligent rogue AI could ‘live’ anywhere with an internet connection – it doesn’t need to take on a physical form.</p>
    <ul><li><strong>AI is programmed to do something destructive</strong></li></ul>
    <p>In the case of weapons development, AI could be programmed to kill, hurt or otherwise destroy people or property. Such devices would not be fielded with a simple means to deactivate them, or they wouldn’t be much good in combat. They’d likely be extremely hard to stop. Additionally, if they did use machine learning to learn from combat situations to improve their tactics or strategy, these learning processes could have unexpected and disastrous consequences.&nbsp;</p>
    <ul start="2"><li><strong>AI Becomes Destructive as a Side Effect</strong></li><p>In the case of weapons development, AI could be programmed to kill, hurt or otherwise destroy people or property. Such devices would not be fielded with a simple means to deactivate them, or they wouldn’t be much good in combat. They’d likely be extremely hard to stop. Additionally, if they did use machine learning to learn from combat situations to improve their tactics or strategy, these learning processes could have unexpected and disastrous consequences.&nbsp;</p></ul>
    <p>AI is generally designed to be relentless in its approach to solving logical issues. Humans are capable of nuance, so for example, we may judge that whilst rerouting a river may prevent flooding, it may also result in tremendous environmental destruction, thus the answer is to not take action at all.&nbsp;</p>
    <p>AI built on the basic logical premise ‘to prevent flooding’ does not have the same liability or capability of nuance, and may go to destructive means to achieve its basic goal. This concept has been explored thoroughly in SciFi where machines once designed to help us turn against us as they begin to see that humans are in the way of the <em>greater good.</em></p>
    <h3><span class="ez-toc-section" id="2_AI_Machines_Dont_Currently_Have_Any_Emotion"></span>2. AI Machines Don’t (Currently) Have Any Emotion<span class="ez-toc-section-end"></span></h3>
    <p>Perhaps then, the solution is to not invent extremely clever AI unless we can also teach it to be kind and compassionate? The problem is, these are still human ideas that might be interpreted differently by intelligent AI. Compassion and kindness are not entirely logical, but distinctly abstract and despite our best efforts to ‘design’ it, we will most likely always fall short of the mark.</p>
    <hr class="wp-block-separator is-style-wide">
    <h3><span class="ez-toc-section" id="3_Degradation"></span>3. Degradation<span class="ez-toc-section-end"></span></h3>
    <p><strong><em>Just because AI can be installed into a machine does not mean it can’t degrade. </em></strong>Human bodies are exceptionally good at regenerating and though we may consider flesh and blood a disadvantage over metal, there are some significant advantages. If the components in an AI system do degrade then unless it is somehow able to self-repair, it will not be able to fix itself and will slowly fail. It may be able to understand what is failing but is still physically powerless to prevent it or repair it. <strong><em>This may be the case where the model training data is now old or outdated.</em></strong></p>
    <p>AI threatens our way of life. At the moment, the public’s appetite for AI is not very high and though we generally see little ‘evidence’ of AI in our day-to-day lives, this will change with automation. Automation threatens the labour market, we’ve seen how Ocado uses a network of robots to deal with warehousing and this scenario is proliferating rapidly potentially threatening millions of jobs worldwide.&nbsp;</p>
    <p>Whilst it might seem a huge advantage to replace humans with more efficient robots, we have to consider where this ends. The Disney film WALL-E encapsulates this well, portraying humans as literal couch-potatoes who have over-consumed planet Earth. What happens to our identity when all of our jobs are gone? What will we do? Can it ever be sustainable?&nbsp;</p>
    <p>The issue is not just sociocultural but political also. For example, in the UK, labour unions such as the CWU, who represents the Royal Mail, have already been <a href="https://tamebay.com/2020/02/royal-mail-transformation-to-roll-out-after-losing-patience-with-cwu-union.html" target="_blank" rel="nofollow">heavily criticising automation plans</a> that put people out of work.</p>
    <h3><span class="ez-toc-section" id="5_High_Costs"></span>5. High Costs<span class="ez-toc-section-end"></span></h3>
    <p>AI varies hugely in cost. If we consider a web scraper designed to scrape just hundreds of webpages then sure, we can run likely run this comfortably off our own internet connection and system resources. Scale this up to millions of webpages and suddenly, you require dedicated servers and powerful systems to run the web scraper efficiently. With AI’s scale comes scaled costs, too. It’s currently not within the grasp of most consumer technology to run complex AI.</p>
    <p>Whilst simple AI is usually not power-hungry, it’s still expensive to run very complex AI. One of Google’s AlphaGo system used over 1000 CPUs and 200 GPUs! Not only are systems like this expensive and tough to build, but they’re also all physically large and not easily transported. This may change with <a href="https://research.google/teams/applied-science/quantum/" target="_blank" rel="nofollow">quantum computing </a>and other developments, but for now, super-powerful AI is expensive and cumbersome. </p>
    <h3><span class="ez-toc-section" id="6_Lacking_Creativity_and_Out-of-the-Box_Thinking"></span>6. Lacking Creativity and Out-of-the-Box Thinking<span class="ez-toc-section-end"></span></h3>
    <p>As mentioned, AI is a logical beast. Numbers, symbols, words; anything data-related can be adeptly consumed and interpreted by AI. But what about abstract thinking and creativity? </p>
    <p>Part of the beauty of the human mind is that it can be fairly volatile and non-linear in the way it works. This may also be a weakness as well, but humans at the cutting edge of knowledge have not been entirely logical or rational thinkers. We rely on our creativity to generate ideas to then explore logically. AI cannot currently do this and lacks the ability to think out-of-the-box. It can be taught set variables and learn to adapt them but this still occurs in-the-box – for now!</p>
    